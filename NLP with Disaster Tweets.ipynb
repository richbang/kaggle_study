{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":29844,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## NLP Tutorial\n\nNLP - or *Natural Language Processing* - is shorthand for a wide array of techniques designed to help machines learn from text. Natural Language Processing powers everything from chatbots to search engines, and is used in diverse tasks like sentiment analysis and machine translation.\n\nIn this tutorial we'll look at this competition's dataset, use a simple technique to process it, build a machine learning model, and submit predictions for a score!","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T04:28:09.405263Z","iopub.execute_input":"2024-06-26T04:28:09.405735Z","iopub.status.idle":"2024-06-26T04:28:12.314639Z","shell.execute_reply.started":"2024-06-26T04:28:09.405655Z","shell.execute_reply":"2024-06-26T04:28:12.313627Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2024-06-26T04:28:12.317225Z","iopub.execute_input":"2024-06-26T04:28:12.317667Z","iopub.status.idle":"2024-06-26T04:28:12.423955Z","shell.execute_reply.started":"2024-06-26T04:28:12.317594Z","shell.execute_reply":"2024-06-26T04:28:12.422911Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### A quick look at our data\n\nLet's look at our data... first, an example of what is NOT a disaster tweet.","metadata":{}},{"cell_type":"code","source":"train_df[train_df[\"target\"] == 0][\"text\"].values[1]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:12.425895Z","iopub.execute_input":"2024-06-26T04:28:12.426403Z","iopub.status.idle":"2024-06-26T04:28:12.447258Z","shell.execute_reply.started":"2024-06-26T04:28:12.426234Z","shell.execute_reply":"2024-06-26T04:28:12.446208Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'I love fruits'"},"metadata":{}}]},{"cell_type":"markdown","source":"And one that is:","metadata":{}},{"cell_type":"code","source":"train_df[train_df[\"target\"] == 1][\"text\"].values[1]","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:12.451702Z","iopub.execute_input":"2024-06-26T04:28:12.452048Z","iopub.status.idle":"2024-06-26T04:28:12.462430Z","shell.execute_reply.started":"2024-06-26T04:28:12.451996Z","shell.execute_reply":"2024-06-26T04:28:12.461472Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'Forest fire near La Ronge Sask. Canada'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Building vectors\n\nThe theory behind the model we'll build in this notebook is pretty simple: the words contained in each tweet are a good indicator of whether they're about a real disaster or not (this is not entirely correct, but it's a great place to start).\n\nWe'll use scikit-learn's `CountVectorizer` to count the words in each tweet and turn them into data our machine learning model can process.\n\nNote: a `vector` is, in this context, a set of numbers that a machine learning model can work with. We'll look at one in just a second.","metadata":{}},{"cell_type":"code","source":"count_vectorizer = feature_extraction.text.CountVectorizer()\n\n## let's get counts for the first 5 tweets in the data\nexample_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:12.466207Z","iopub.execute_input":"2024-06-26T04:28:12.466573Z","iopub.status.idle":"2024-06-26T04:28:12.483242Z","shell.execute_reply.started":"2024-06-26T04:28:12.466509Z","shell.execute_reply":"2024-06-26T04:28:12.482167Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\nprint(example_train_vectors[0].todense().shape)\nprint(example_train_vectors[0].todense())","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:12.485491Z","iopub.execute_input":"2024-06-26T04:28:12.485866Z","iopub.status.idle":"2024-06-26T04:28:12.496969Z","shell.execute_reply.started":"2024-06-26T04:28:12.485799Z","shell.execute_reply":"2024-06-26T04:28:12.496075Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(1, 54)\n[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The above tells us that:\n1. There are 54 unique words (or \"tokens\") in the first five tweets.\n2. The first tweet contains only some of those unique tokens - all of the non-zero counts above are the tokens that DO exist in the first tweet.\n\nNow let's create vectors for all of our tweets.","metadata":{}},{"cell_type":"code","source":"train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n\n## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n# that the tokens in the train vectors are the only ones mapped to the test vectors - \n# i.e. that the train and test vectors use the same set of tokens.\ntest_vectors = count_vectorizer.transform(test_df[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:12.498914Z","iopub.execute_input":"2024-06-26T04:28:12.499229Z","iopub.status.idle":"2024-06-26T04:28:13.031243Z","shell.execute_reply.started":"2024-06-26T04:28:12.499165Z","shell.execute_reply":"2024-06-26T04:28:13.030007Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Our model\n\nAs we mentioned above, we think the words contained in each tweet are a good indicator of whether they're about a real disaster or not. The presence of particular word (or set of words) in a tweet might link directly to whether or not that tweet is real.\n\nWhat we're assuming here is a _linear_ connection. So let's build a linear model and see!","metadata":{}},{"cell_type":"code","source":"## Our vectors are really big, so we want to push our model's weights\n## toward 0 without completely discounting different words - ridge regression \n## is a good way to do this.\nclf = linear_model.RidgeClassifier()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:13.032849Z","iopub.execute_input":"2024-06-26T04:28:13.033180Z","iopub.status.idle":"2024-06-26T04:28:13.037976Z","shell.execute_reply.started":"2024-06-26T04:28:13.033121Z","shell.execute_reply":"2024-06-26T04:28:13.036949Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Let's test our model and see how well it does on the training data. For this we'll use `cross-validation` - where we train on a portion of the known data, then validate it with the rest. If we do this several times (with different portions) we can get a good idea for how a particular model or method performs.\n\nThe metric for this competition is F1, so let's use that here.","metadata":{}},{"cell_type":"code","source":"scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\nscores","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:13.039532Z","iopub.execute_input":"2024-06-26T04:28:13.039839Z","iopub.status.idle":"2024-06-26T04:28:14.388112Z","shell.execute_reply.started":"2024-06-26T04:28:13.039789Z","shell.execute_reply":"2024-06-26T04:28:14.386839Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([0.60387232, 0.57484457, 0.64485082])"},"metadata":{}}]},{"cell_type":"markdown","source":"The above scores aren't terrible! It looks like our assumption will score roughly 0.65 on the leaderboard. There are lots of ways to potentially improve on this (TFIDF, LSA, LSTM / RNNs, the list is long!) - give any of them a shot!\n\nIn the meantime, let's do predictions on our training set and build a submission for the competition.","metadata":{}},{"cell_type":"code","source":"clf.fit(train_vectors, train_df[\"target\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:14.389995Z","iopub.execute_input":"2024-06-26T04:28:14.390403Z","iopub.status.idle":"2024-06-26T04:28:15.102973Z","shell.execute_reply.started":"2024-06-26T04:28:14.390345Z","shell.execute_reply":"2024-06-26T04:28:15.101924Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n                max_iter=None, normalize=False, random_state=None,\n                solver='auto', tol=0.001)"},"metadata":{}}]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:15.104807Z","iopub.execute_input":"2024-06-26T04:28:15.105187Z","iopub.status.idle":"2024-06-26T04:28:15.123677Z","shell.execute_reply.started":"2024-06-26T04:28:15.105130Z","shell.execute_reply":"2024-06-26T04:28:15.122509Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sample_submission[\"target\"] = clf.predict(test_vectors)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:15.125556Z","iopub.execute_input":"2024-06-26T04:28:15.125996Z","iopub.status.idle":"2024-06-26T04:28:15.132668Z","shell.execute_reply.started":"2024-06-26T04:28:15.125911Z","shell.execute_reply":"2024-06-26T04:28:15.131616Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:15.134709Z","iopub.execute_input":"2024-06-26T04:28:15.135166Z","iopub.status.idle":"2024-06-26T04:28:15.157792Z","shell.execute_reply.started":"2024-06-26T04:28:15.135088Z","shell.execute_reply":"2024-06-26T04:28:15.156765Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       0\n1   2       1\n2   3       1\n3   9       0\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:15.159336Z","iopub.execute_input":"2024-06-26T04:28:15.159686Z","iopub.status.idle":"2024-06-26T04:28:15.705987Z","shell.execute_reply.started":"2024-06-26T04:28:15.159618Z","shell.execute_reply":"2024-06-26T04:28:15.704917Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(train_df.columns)    \nprint('---')\nif 0 in train_df['target']:\n    print('true')\n    \nfor i in range(0,len(train_df['target'])):\n    if train_df['target'][i] == 0:\n        print(f'index: {i} is 0')\n    if i is 20:\n        break\nprint('---')        \nfor i in range(0, len(train_df['location'])):\n    if isinstance(train_df['location'][i], (list, str)):\n        print(train_df['location'][i])\n    if i is 40:\n        break\nprint('---')\nsize=len(train_df['id'])\n\ncount_with_location=0\ncount_without_location=0\nfor i in range(0, size):\n    if isinstance(train_df['location'][i], (list, str)) == 1 and train_df['target'][i] == 1:\n        #print(train_df['id'][i])\n        count_with_location+=1\n    elif isinstance(train_df['location'][i], (list, str)) == 0 and train_df['target'][i] == 1:\n        count_without_location+=1\nprint(count_with_location) # 2196\nprint(count_without_location) # 1075\\\nprint('---')\ncount_with_keyword=0\ncount_without_keyword=0\nfor i in range(0, size):\n    if train_df['target'][i]==1 and isinstance(train_df['keyword'][i],(list,str))==1:\n        count_with_keyword+=1\n    elif train_df['target'][i]==1 and isinstance(train_df['keyword'][i],(list,str))==0:\n        count_without_keyword+=1\nprint(count_with_keyword, count_without_keyword) # 3229, 42","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:15.707396Z","iopub.execute_input":"2024-06-26T04:28:15.707684Z","iopub.status.idle":"2024-06-26T04:28:16.570232Z","shell.execute_reply.started":"2024-06-26T04:28:15.707636Z","shell.execute_reply":"2024-06-26T04:28:16.569161Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n---\ntrue\nindex: 15 is 0\nindex: 16 is 0\nindex: 17 is 0\nindex: 18 is 0\nindex: 19 is 0\nindex: 20 is 0\n---\nBirmingham\nEst. September 2012 - Bristol\nAFRICA\nPhiladelphia, PA\nLondon, UK\nPretoria\nWorld Wide!!\nParanaque City\nLive On Webcam\n---\n2196\n1075\n---\n3229 42\n","output_type":"stream"}]},{"cell_type":"code","source":"correlation_matrix=train_df.corr(method='spearman')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:16.571895Z","iopub.execute_input":"2024-06-26T04:28:16.572200Z","iopub.status.idle":"2024-06-26T04:28:16.588172Z","shell.execute_reply.started":"2024-06-26T04:28:16.572150Z","shell.execute_reply":"2024-06-26T04:28:16.587138Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(correlation_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:16.590356Z","iopub.execute_input":"2024-06-26T04:28:16.590802Z","iopub.status.idle":"2024-06-26T04:28:16.607108Z","shell.execute_reply.started":"2024-06-26T04:28:16.590724Z","shell.execute_reply":"2024-06-26T04:28:16.606076Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"              id    target\nid      1.000000  0.060789\ntarget  0.060789  1.000000\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ndf = pd.DataFrame(train_df)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:16.608832Z","iopub.execute_input":"2024-06-26T04:28:16.609194Z","iopub.status.idle":"2024-06-26T04:28:16.616767Z","shell.execute_reply.started":"2024-06-26T04:28:16.609133Z","shell.execute_reply":"2024-06-26T04:28:16.615859Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df['keyword'] = df['keyword'].fillna('missing').astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:16.618760Z","iopub.execute_input":"2024-06-26T04:28:16.619260Z","iopub.status.idle":"2024-06-26T04:28:16.634563Z","shell.execute_reply.started":"2024-06-26T04:28:16.619197Z","shell.execute_reply":"2024-06-26T04:28:16.633345Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df['keyword_encoded'] = label_encoder.fit_transform(df['keyword'])\n\ncorrelation_matrix = df[['target', 'keyword_encoded']].corr(method='pearson')\nprint(correlation_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:28:16.636174Z","iopub.execute_input":"2024-06-26T04:28:16.636570Z","iopub.status.idle":"2024-06-26T04:28:16.656770Z","shell.execute_reply.started":"2024-06-26T04:28:16.636516Z","shell.execute_reply":"2024-06-26T04:28:16.655765Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"                   target  keyword_encoded\ntarget           1.000000         0.057669\nkeyword_encoded  0.057669         1.000000\n","output_type":"stream"}]},{"cell_type":"code","source":"a = [2, 3, 10]\nprint(np.arange(len(a)))","metadata":{"execution":{"iopub.status.busy":"2024-06-26T04:41:11.394955Z","iopub.execute_input":"2024-06-26T04:41:11.395427Z","iopub.status.idle":"2024-06-26T04:41:11.402163Z","shell.execute_reply.started":"2024-06-26T04:41:11.395345Z","shell.execute_reply":"2024-06-26T04:41:11.400893Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[0 1 2]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, in the viewer, you can submit the above file to the competition! Good luck!","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nclass MyKFold:\n    def __init__(self, n_splits=5, shuffle=False, random_state=None):\n        self.n_splits = n_splits\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n    def split(self, X):\n        n_samples = len(X)\n        indices = np.arange(n_samples)\n        \n        if self.shuffle:\n            np.random.seed(self.random_state)\n            np.random.shuffle(indices)\n        \n        fold_sizes = np.full(self.n_splits, n_samples // self.n_splits, dtype=int)\n        # np.full(shape, fill_value, dtype=None)  shape과 dtype을 갖는 배열을 생성함. 이 배열의 모든 요소를 fill_value로 채움\n        fold_sizes[:n_samples % self.n_splits] += 1\n        \n        current = 0\n        for fold_size in fold_sizes:\n            start, stop = current, current + fold_size\n            # start는 현재 폴드의 시작 인덱스, stop은 현재 폴드의 끝 인덱스\n            # fold_sizes는 각 폴드에 포함될 샘플의 수\n            # 각 폴드의 크기를 fold_size 변수에 할당함\n            test_indices = indices[start:stop]\n            # indices 배열에서 현재 폴드에 해당하는 부분을 잘라내어 test_indices에 저장함\n            # 예를 들어, indices가 [0, 1, 2, ..., 99]이고, start가 0, stop이 20이면 test_indices는 [0, 1, 2, ..., 19]가 됨\n            train_indices = np.concatenate([indices[:start], indices[stop:]])\n            # indices 배열에서 현재 폴드를 제외한 나머지 부분을 이어붙여 train_indices에 저장함\n            # 예를 들어, start가 0, stop이 20이면 train_indices는 [20, 21, 22, ..., 99]가 됨\n            yield train_indices, test_indices\n            # 현재 폴드의 학습 인덱스와 테스트 인덱스를 생성기로 반환함\n            # yield는 함수의 상태를 저장하고, 나중에 다시 호출되면 저장된 상태에서 계속 실행됨\n            current = stop\n            # 다음 폴드를 위한 현재 인덱스 갱신\n            # current를 현재 폴드의 끝 인덱스로 갱신하여 다음 폴드의 시작 인덱스로 사용함\n            \n# 사용 예제\nX = np.arange(20)  # 예시 데이터\nkf = MyKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor train_index, test_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T05:09:57.706987Z","iopub.execute_input":"2024-06-26T05:09:57.707381Z","iopub.status.idle":"2024-06-26T05:09:57.728275Z","shell.execute_reply.started":"2024-06-26T05:09:57.707327Z","shell.execute_reply":"2024-06-26T05:09:57.727129Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"TRAIN: [ 8  5 11  3 18 16 13  2  9 19  4 12  7 10 14  6] TEST: [ 0 17 15  1]\nTRAIN: [ 0 17 15  1 18 16 13  2  9 19  4 12  7 10 14  6] TEST: [ 8  5 11  3]\nTRAIN: [ 0 17 15  1  8  5 11  3  9 19  4 12  7 10 14  6] TEST: [18 16 13  2]\nTRAIN: [ 0 17 15  1  8  5 11  3 18 16 13  2  7 10 14  6] TEST: [ 9 19  4 12]\nTRAIN: [ 0 17 15  1  8  5 11  3 18 16 13  2  9 19  4 12] TEST: [ 7 10 14  6]\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_folds(X, y, k):\n    kf = MyKFold(n_splits=k, shuffle=True, random_state=42)\n    folds = list(kf.split(X))\n    return folds","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:18:47.871409Z","iopub.execute_input":"2024-06-26T07:18:47.871823Z","iopub.status.idle":"2024-06-26T07:18:47.878157Z","shell.execute_reply.started":"2024-06-26T07:18:47.871769Z","shell.execute_reply":"2024-06-26T07:18:47.876966Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def precision_recall_f1(y_true, y_pred):\n    # TP : 양성으로 예측한 것이 실제 양성인 경우\n    tp = sum((y_pred == 1) & (y_true == 1))\n    # FP : 양성으로 예측한 것이 실제 음성인 경우\n    fp = sum((y_pred == 1) & (y_true == 0))\n    # FN : 음성으로 예측한 것이 실제 양성인 경우\n    fn = sum((y_pred == 0) & (y_true == 1))\n    \n    # Precision 계산\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    \n    # Recall 계산\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    \n    # F1 Score 계산\n    f1_score = 2 * ((precision*recall) / (precision+recall)) if (precision + recall) > 0 else 0\n    \n    return precision, recall, f1_score\n\n# 예시 데이터\ny_true = np.array([0, 1, 1, 1, 0, 1, 0, 0, 1, 0])\ny_pred = np.array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0])\n\nprecision, recall, f1 = precision_recall_f1(y_true, y_pred)\nprint(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T05:34:34.040337Z","iopub.execute_input":"2024-06-26T05:34:34.040807Z","iopub.status.idle":"2024-06-26T05:34:34.056576Z","shell.execute_reply.started":"2024-06-26T05:34:34.040730Z","shell.execute_reply":"2024-06-26T05:34:34.055290Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Precision: 0.8, Recall: 0.8, F1 Score: 0.8000000000000002\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_evaluate(clf, X, y, folds):\n    scores = []\n    for train_index, test_index in folds:\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        \n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        \n        score = f1_score(y_test, y_pred)\n        scores.append(score)\n        \n    return scores","metadata":{"execution":{"iopub.status.busy":"2024-06-26T05:43:47.736148Z","iopub.execute_input":"2024-06-26T05:43:47.736574Z","iopub.status.idle":"2024-06-26T05:43:47.744991Z","shell.execute_reply.started":"2024-06-26T05:43:47.736512Z","shell.execute_reply":"2024-06-26T05:43:47.743786Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def cross_val_score_manual(clf, X, y, k):\n    folds = create_folds(X, y, k)\n    scores = train_and_evaluate(clf, X, y, folds)\n    return np.mean(scores), np.std(scores)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T05:45:54.325282Z","iopub.execute_input":"2024-06-26T05:45:54.325733Z","iopub.status.idle":"2024-06-26T05:45:54.332911Z","shell.execute_reply.started":"2024-06-26T05:45:54.325671Z","shell.execute_reply":"2024-06-26T05:45:54.331645Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def kfold_cross_validation(model, data, labels, k):\n    kf = MyKFold(n_splits = k, shuffle = True, random_state = 42)\n    scores = []\n    \n    for train_index, test_index in kf.split(data):\n        X_train, X_test = data[train_index], data[test_index]\n        y_train, y_test = labels[train_index], labels[test_index]\n        \n        model.fit(X_train, y_train)\n        \n        predictions = model.predict(X_test)\n        score = precision_recall_f1(y_test, predictions)\n        scores.append(score)\n        \n    mean_score = np.mean(scores)\n    return mean_score","metadata":{"execution":{"iopub.status.busy":"2024-06-26T05:53:53.537348Z","iopub.execute_input":"2024-06-26T05:53:53.537818Z","iopub.status.idle":"2024-06-26T05:53:53.547562Z","shell.execute_reply.started":"2024-06-26T05:53:53.537740Z","shell.execute_reply":"2024-06-26T05:53:53.546506Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T05:58:29.958622Z","iopub.execute_input":"2024-06-26T05:58:29.959071Z","iopub.status.idle":"2024-06-26T05:58:29.975775Z","shell.execute_reply.started":"2024-06-26T05:58:29.958997Z","shell.execute_reply":"2024-06-26T05:58:29.974829Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"id                    0\nkeyword               0\nlocation           2533\ntext                  0\ntarget                0\nkeyword_encoded       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df=train_df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T05:59:33.709007Z","iopub.execute_input":"2024-06-26T05:59:33.709435Z","iopub.status.idle":"2024-06-26T05:59:33.731764Z","shell.execute_reply.started":"2024-06-26T05:59:33.709379Z","shell.execute_reply":"2024-06-26T05:59:33.730818Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T05:59:49.855177Z","iopub.execute_input":"2024-06-26T05:59:49.855577Z","iopub.status.idle":"2024-06-26T05:59:49.867875Z","shell.execute_reply.started":"2024-06-26T05:59:49.855520Z","shell.execute_reply":"2024-06-26T05:59:49.866798Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"id                 0\nkeyword            0\nlocation           0\ntext               0\ntarget             0\nkeyword_encoded    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    text = text.lower()\n    text = re.sub(r'\\W', ' ', text)\n    text = re.sub(r'\\s+', ' ', text)\n    text = re.sub(r'\\d', ' ', text)\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n    return text\n\ndf['cleaned_text'] = df['text'].apply(preprocess_text)\ndf['tokens'] = df['cleaned_text'].apply(word_tokenize)\n\n# 디버깅 포인트: 결과 확인\nprint(df[['text', 'cleaned_text', 'tokens']].head())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:24:40.649148Z","iopub.execute_input":"2024-06-26T07:24:40.649671Z","iopub.status.idle":"2024-06-26T07:24:42.098734Z","shell.execute_reply.started":"2024-06-26T07:24:40.649574Z","shell.execute_reply":"2024-06-26T07:24:42.097860Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  from ipykernel import kernelapp as app\n","output_type":"stream"},{"name":"stdout","text":"                                                 text  \\\n31  @bbcmtd Wholesale Markets ablaze http://t.co/l...   \n32  We always try to bring the heavy. #metal #RT h...   \n33  #AFRICANBAZE: Breaking news:Nigeria flag set a...   \n34                 Crying out for more! Set me ablaze   \n35  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...   \n\n                                         cleaned_text  \\\n31  bbcmtd wholesale markets ablaze http co lhyxeo...   \n32  always try bring heavy metal rt http co yao e ...   \n33  africanbaze breaking news nigeria flag set abl...   \n34                                  crying set ablaze   \n35  plus side look sky last night ablaze http co q...   \n\n                                               tokens  \n31  [bbcmtd, wholesale, markets, ablaze, http, co,...  \n32  [always, try, bring, heavy, metal, rt, http, c...  \n33  [africanbaze, breaking, news, nigeria, flag, s...  \n34                              [crying, set, ablaze]  \n35  [plus, side, look, sky, last, night, ablaze, h...  \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  app.launch_new_instance()\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(max_features=5000)\nX = tfidf.fit_transform(df['cleaned_text']).toarray()\n\n# 디버깅 포인트: TF-IDF 결과 확인\nprint(X.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:25:01.298895Z","iopub.execute_input":"2024-06-26T07:25:01.299267Z","iopub.status.idle":"2024-06-26T07:25:01.716463Z","shell.execute_reply.started":"2024-06-26T07:25:01.299211Z","shell.execute_reply":"2024-06-26T07:25:01.715348Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"(5080, 5000)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = df['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 디버깅 포인트: 데이터 분할 결과 확인\nprint(X_train.shape, X_test.shape)\nprint(y_train.shape, y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:25:10.460259Z","iopub.execute_input":"2024-06-26T07:25:10.460719Z","iopub.status.idle":"2024-06-26T07:25:10.643028Z","shell.execute_reply.started":"2024-06-26T07:25:10.460646Z","shell.execute_reply":"2024-06-26T07:25:10.641851Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"(4064, 5000) (1016, 5000)\n(4064,) (1016,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:25:14.878972Z","iopub.execute_input":"2024-06-26T07:25:14.879391Z","iopub.status.idle":"2024-06-26T07:25:14.960479Z","shell.execute_reply.started":"2024-06-26T07:25:14.879331Z","shell.execute_reply":"2024-06-26T07:25:14.959455Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n                   multi_class='warn', n_jobs=None, penalty='l2',\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:25:19.836001Z","iopub.execute_input":"2024-06-26T07:25:19.836376Z","iopub.status.idle":"2024-06-26T07:25:19.863466Z","shell.execute_reply.started":"2024-06-26T07:25:19.836303Z","shell.execute_reply":"2024-06-26T07:25:19.862175Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.78      0.89      0.83       580\n           1       0.82      0.66      0.73       436\n\n    accuracy                           0.79      1016\n   macro avg       0.80      0.77      0.78      1016\nweighted avg       0.79      0.79      0.79      1016\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, X, y, cv=5, scoring='f1')\nprint(f\"Cross-Validation F1 Scores: {scores}\")\nprint(f\"Mean F1 Score: {scores.mean()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:25:24.040212Z","iopub.execute_input":"2024-06-26T07:25:24.040579Z","iopub.status.idle":"2024-06-26T07:25:25.145068Z","shell.execute_reply.started":"2024-06-26T07:25:24.040519Z","shell.execute_reply":"2024-06-26T07:25:25.143458Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","output_type":"stream"},{"name":"stdout","text":"Cross-Validation F1 Scores: [0.56278366 0.57065217 0.58366801 0.48909657 0.68157895]\nMean F1 Score: 0.5775558721928912\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}